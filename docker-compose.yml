services:
  # DGraph Zero - Cluster management
  dgraph-zero:
    image: dgraph/dgraph:v24.0.0
    container_name: rmk-dgraph-zero
    ports:
      - "5080:5080"
      - "6080:6080"
    volumes:
      - dgraph-zero-data:/dgraph
    command: dgraph zero --my=dgraph-zero:5080
    networks:
      - rmk-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:6080/health" ]
      interval: 10s
      timeout: 5s
      retries: 5

  # DGraph Alpha - Graph database
  dgraph-alpha:
    image: dgraph/dgraph:v24.0.0
    container_name: rmk-dgraph-alpha
    ports:
      - "18080:8080"
      - "19080:9080"
    volumes:
      - dgraph-alpha-data:/dgraph
    command: dgraph alpha --my=dgraph-alpha:7080 --zero=dgraph-zero:5080 --security whitelist=0.0.0.0/0

    networks:
      - rmk-network
    depends_on:
      dgraph-zero:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/health" ]
      interval: 10s
      timeout: 5s
      retries: 5

  # NATS - Message queue for streaming
  nats:
    image: nats:alpine
    container_name: rmk-nats
    ports:
      - "4322:4222"
      - "8322:8222"
    command: [ "--jetstream", "--http_port", "8222" ]
    networks:
      - rmk-network
    healthcheck:
      test: [ "CMD", "wget", "--spider", "-q", "http://localhost:8222/healthz" ]
      interval: 5s
      timeout: 3s
      retries: 5

  # Redis - Caching activation scores and hot paths
  redis:
    image: redis:7-alpine
    container_name: rmk-redis
    ports:
      - "6479:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    networks:
      - rmk-network
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 5s
      timeout: 3s
      retries: 5

  # AI Services - Go gnet-based server for SLM orchestration
  # Replaces Python FastAPI with high-performance Go implementation
  ai-services:
    build:
      context: .
      dockerfile: Dockerfile.ai-service
    container_name: rmk-ai-services
    ports:
      - "8000:8000"
    environment:
      - GLM_API_KEY=${GLM_API_KEY:-}
      - NVIDIA_API_KEY=${NVIDIA_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OLLAMA_URL=http://ollama:11434
      - AI_SERVICE_HOST=0.0.0.0
      - AI_SERVICE_PORT=8000
      - LOG_LEVEL=info
      - AI_CLASSIFICATION_TIMEOUT=15s
    networks:
      - rmk-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Ollama - Local LLM/Embedding service (replaces ONNX)
  ollama:
    image: ollama/ollama:latest
    container_name: rmk-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - rmk-network
    entrypoint: ["/bin/sh", "-c", "ollama serve & sleep 10 && ollama pull nomic-embed-text && sleep infinity"]
    healthcheck:
      test: [ "CMD-SHELL", "ollama list | grep nomic-embed-text || exit 1" ]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 120s

  # Qdrant - Vector database for Hybrid RAG
  qdrant:
    image: qdrant/qdrant:latest
    container_name: rmk-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-data:/qdrant/storage
    networks:
      - rmk-network
    healthcheck:
      test: [ "CMD-SHELL", "timeout 3 bash -c 'cat < /dev/null > /dev/tcp/localhost/6333' || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Inngest - Durable execution for workflows
  inngest:
    image: inngest/inngest:latest
    container_name: rmk-inngest
    command: ["/bin/sh", "-c", "exec /usr/bin/inngest dev"]
    ports:
      - "8288:8288"
      - "8283:8283"
    environment:
      - INNGEST_EVENT_KEY=${INNGEST_EVENT_KEY:-test-event-key}
      - INNGEST_SIGNING_KEY=${INNGEST_SIGNING_KEY:-test-signing-key}
      - INNGEST_DATABASE_POSTGRES_STRING=postgresql://postgres:postgres@inngest-db:5432/inngest
      - INNGEST_JOBS_DATABASE_POSTGRES_STRING=postgresql://postgres:postgres@inngest-db:5432/inngest
      - INNGEST_ENV=dev
    networks:
      - rmk-network
    depends_on:
      - inngest-db
    # Disable healthcheck for now - inngest image doesn't have wget/curl
    # and the service logs show it's running fine

  # Inngest PostgreSQL - Database for Inngest state
  inngest-db:
    image: postgres:15-alpine
    container_name: rmk-inngest-db
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=inngest
    volumes:
      - inngest-db-data:/var/lib/postgresql/data
    networks:
      - rmk-network
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "postgres" ]
      interval: 5s
      timeout: 3s
      retries: 5

  # Workflow Worker - Inngest workflow processor for RMK
  workflow-worker:
    build:
      context: .
      dockerfile: Dockerfile.workflow
    container_name: rmk-workflow-worker
    ports:
      - "8082:8082"
    environment:
      - DGRAPH_ADDRESS=dgraph-alpha:9080
      - INNGEST_API_KEY=${INNGEST_SIGNING_KEY:-test-signing-key}
      - INNGEST_EVENT_KEY=${INNGEST_EVENT_KEY:-test-event-key}
      - INNGEST_APP_ID=rmk-workflows
      - OLLAMA_URL=http://ollama:11434
      - LOG_LEVEL=info
      - ADDR=:8082
    networks:
      - rmk-network
    depends_on:
      - dgraph-alpha
      - ollama
      - inngest
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8082/health" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Monolith - Unified Agent + Kernel (Quantum Architecture)
  monolith:
    build:
      context: .
      dockerfile: Dockerfile.monolith
    container_name: rmk-monolith
    ports:
      - "8080:8080"
    environment:
      - DGRAPH_ADDRESS=dgraph-alpha:9080
      - NATS_URL=nats://nats:4222
      - REDIS_ADDRESS=redis:6379
      - AI_SERVICES_URL=http://ai-services:8000
      - OLLAMA_URL=http://ollama:11434
      - QDRANT_URL=http://qdrant:6333
      - JWT_SECRET=${JWT_SECRET:-dev-secret-change-in-production-32chars-minimum-length}
      - PORT=8080
      - FRONTEND_ONLY=${FRONTEND_ONLY:-false}
    networks:
      - rmk-network
    depends_on:
      dgraph-alpha:
        condition: service_healthy
      nats:
        condition: service_healthy
      redis:
        condition: service_healthy
      ai-services:
        condition: service_started
      ollama:
        condition: service_healthy
      qdrant:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/health" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
  # NOTE: Frontend is embedded in monolith - no separate container needed
  # The monolith serves the React SPA from /app/static (built during Docker build)
  # Access the full app at http://localhost:8080

volumes:
  dgraph-zero-data:
  dgraph-alpha-data:
  redis-data:
  ollama-data:
  qdrant-data:
  inngest-db-data:


networks:
  rmk-network:
    driver: bridge
